{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sentiment Analysis, IMdb.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "a5ndLtaz9Fgy",
        "uIaToE3_r2_f",
        "QGQ9aADFPqaz",
        "l_fjg0QZgZCa",
        "7ogYITVq35eG",
        "5LC04oP7ljyP",
        "-3lqU19BPBcx",
        "YryHaIbCPGSj",
        "_C4Trwp-sh_T",
        "YHjkJk0NX-27",
        "4KZ7_dQtoeA0",
        "OM-fJ6Jd8M9S",
        "WJtSfokdJ-7-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a70de0f923ee4c69b751d7033baa86c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_932647eefdb549f1b6be741872cdc91e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58d4d1448c764e3fa6bea56dd3f6787f",
              "IPY_MODEL_620c9a40b8fc4345919e98827e97594a"
            ]
          }
        },
        "932647eefdb549f1b6be741872cdc91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58d4d1448c764e3fa6bea56dd3f6787f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56d6a93ea50f46768b97b081f4b74b30",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae31ea2d2094447495775cd7e45b5915"
          }
        },
        "620c9a40b8fc4345919e98827e97594a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a2770c9b81a460da3a8520cfacf54ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 826kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1a00c27944f4631b8d27c05b52b3a18"
          }
        },
        "56d6a93ea50f46768b97b081f4b74b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae31ea2d2094447495775cd7e45b5915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a2770c9b81a460da3a8520cfacf54ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1a00c27944f4631b8d27c05b52b3a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3889329e10e346d8a609d94eb33b705a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5cebf6197fbc44dbb5f3bb669924ca06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5a8326db6c64eddbd62e7cd588e1020",
              "IPY_MODEL_94e5af6bd18441ceb1915ace9172e58b"
            ]
          }
        },
        "5cebf6197fbc44dbb5f3bb669924ca06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5a8326db6c64eddbd62e7cd588e1020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aac0710a3ad84c52a3b26c38dafc4203",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 546,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 546,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a4b6275d4034f1d82c19bb9e3c54c6e"
          }
        },
        "94e5af6bd18441ceb1915ace9172e58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_871f594f02f84c1eb4f0054429ec0a0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 546/546 [00:08&lt;00:00, 64.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b94ff2b76ff94d88a096beb2d73cb351"
          }
        },
        "aac0710a3ad84c52a3b26c38dafc4203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a4b6275d4034f1d82c19bb9e3c54c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "871f594f02f84c1eb4f0054429ec0a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b94ff2b76ff94d88a096beb2d73cb351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bbcb37539ab41c2845b1f566be71cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32f56de0b34a4d5d8ec7e6948590c952",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f9123ac1b674fde881425899994c542",
              "IPY_MODEL_963db1db61844df18c85e2ff0b5f63db"
            ]
          }
        },
        "32f56de0b34a4d5d8ec7e6948590c952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f9123ac1b674fde881425899994c542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ca75792a78843b2b126a133a49b1201",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e9a9d92814f4309a020fcc0ec98e554"
          }
        },
        "963db1db61844df18c85e2ff0b5f63db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_491547c6bce443d68212e7afe7844bf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:07&lt;00:00, 34.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2ff7999ef294352906687e8904e0d05"
          }
        },
        "5ca75792a78843b2b126a133a49b1201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e9a9d92814f4309a020fcc0ec98e554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "491547c6bce443d68212e7afe7844bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2ff7999ef294352906687e8904e0d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kabongosalomon/Word-Embedding-Investigation/blob/master/%5BTransformer%2C%20BERT%5D%20An%20empirical%20investigation%20into%20the%20properties%20of%20standard%20word%20embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-zPdBDab5P3I"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Kabongosalomon/Data-Science-With-Jeff-Sander/master/aims-za-logo.jpg\" width=\"100\" alt=\"cognitiveclass.ai logo\" />\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v2BR2njWxZFx"
      },
      "source": [
        "# IMdb Sentiment Analysis Task\n",
        "\n",
        "## Importing usefull packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FGvhB20yetpY",
        "outputId": "17dcf046-fe3b-4fcf-f77a-216e1dcd4f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "import tensorflow as tf\n",
        "!pip install transformers\n",
        "import transformers as ppb\n",
        "\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Downgrate numpy to fix a problem\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import string\n",
        "\n",
        "!pip install ipdb\n",
        "import ipdb # deb\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "# Spliting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import metrics # For RUC\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import logging\n",
        "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 26.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=e0203d7ff3aabffcaa93c0392afe3e44a8cbf8e1b9eaf69a8a45810c10cdf7f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/bb/a3e1a441719ebd75c6dac8170d3ddba884b7ee8a5c0f9aefa7297386627a/ipdb-0.13.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (46.1.3)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (1.12.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.1.9)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.2-cp36-none-any.whl size=10522 sha256=abdca7bd6d5d5553640afc18670f66b2e9c1aa31832f36eb596c08a9e29a44b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/c2/15/793365e3c9318c46ba914263740d90f1fe67f544b979141ce4\n",
            "Successfully built ipdb\n",
            "Installing collected packages: ipdb\n",
            "Successfully installed ipdb-0.13.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kkBQByui3Fkt",
        "outputId": "f7d5e5a2-4158-490e-fc62-d5d1399cd1ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "link = \"https://drive.google.com/file/d/1smGRs2g2HoI6VSvonoZmWKzXOP6uPUaW/view?usp=sharing\"\n",
        "\n",
        "_, id_t = link.split('d/')\n",
        "\n",
        "id = id_t.split('/')[0]\n",
        "print (id) # Verify that you have everything after '='\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "file_id = id\n",
        "downloaded = drive.CreateFile({'id':file_id})\n",
        "downloaded.FetchMetadata(fetch_all=True)\n",
        "downloaded.GetContentFile(downloaded.metadata['title'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1smGRs2g2HoI6VSvonoZmWKzXOP6uPUaW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JPqYr6Sj3Fk1",
        "outputId": "908b7177-de7d-4eab-e4bd-e7af2af02e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb.zip  adc.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VVDNN97A3Fk5",
        "colab": {}
      },
      "source": [
        "!unzip -qq aclImdb.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YI_7DRX93Fk-",
        "outputId": "6eb077b2-1251-4863-bbb4-e5ea19458b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb  aclImdb.zip  adc.json\t__MACOSX  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lk-Tubsp3FlO",
        "colab": {}
      },
      "source": [
        "# imdb_dir = './data/aclImdb'\n",
        "imdb_dir = './aclImdb'\n",
        "\n",
        "# Reading in the training folder\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "texts_tr_ = []\n",
        "labels_tr = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname), encoding=\"utf8\")\n",
        "            texts_tr_.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels_tr.append(0)\n",
        "            else:\n",
        "                labels_tr.append(1)\n",
        "\n",
        "# Reading in the testing folder\n",
        "train_dir = os.path.join(imdb_dir, 'test')\n",
        "texts_tst_ = []\n",
        "labels_tst = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname), encoding=\"utf8\")\n",
        "            texts_tst_.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels_tst.append(0)\n",
        "            else:\n",
        "                labels_tst.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "78MzBKaa3FlR",
        "outputId": "65927f29-8847-4898-97ee-fc1945193305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Make sure that we have only 1 and 2 in the label \n",
        "(np.unique(labels_tr), np.unique(labels_tst))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([0, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2-IQncq-pYoD",
        "outputId": "47aefe39-cb1c-47e2-8612-0b4df87d3983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(labels_tr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lt4p5jWS2cXt",
        "outputId": "e4f506de-ffa3-416e-d303-30e9e9d8e2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# Looking at 2 examples\n",
        "print(texts_tr_[1])\n",
        "print(labels_tr[1])\n",
        "\n",
        "print(texts_tst_[-10])\n",
        "print(labels_tst[-10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are movies that are awful, and there are movies that are so awful they are deemed long-forgotten and unwatchable. Also, lots of violence and bad stuff (not just cheesy stuff; you know what I mean) add to the mix as well. What is the result of bad movies with such raunchy content? Why, \"Final Justice,\" of course! <br /><br />Remember \"Mitchell?\" Joe Don Baker was the star of that movie, and that was riffed by Joel and the Bots on \"Mystery Science Theater 3000.\" Now this time, with Mike taking Joel's place on the Satellite of Love (but with the same bots), that trio got to make fun of MST3K's second Joe Don Baker movie, \"Final Justice.\" Of course, much of the naughty stuff that I mentioned was removed for television release, but still, I want to watch that episode (and \"Mitchell\" as well), because what does Joe Don \"hate\" the most? Why, none other than \"Mystery Science Theater 3000!\" <br /><br />P.S. If you have a Big Lots nearby, check that store for the uncut tape! LOL That happened to another user!\n",
            "0\n",
            "An assassination thriller in the mould of Day Of The Jackal, In The Line Of Fire has the added twist that Eastwood's old-timer bodyguard Frank Horrigan is troubled by past failure on the job. The chase becomes personal as John Malkovich's reptilian assassin Leary taunts him over this neurosis - with the rather clunky exception of the love of a good woman (Russo's Lilly Raines) nothing's going to set Frank's mind at rest than taking Leary down personally.<br /><br />Malkovich is a volatile presence - not simply combustible on screen but often a changeable actor too. This is one of his good films, focused and playing director Petersen's game. Eastwood is too old but a) the audience don't care, cos it's him and b) his age is written into the script, not only in the narrative but also as a recurring joke. Pretty much as you'd expect but well-handled. 7/10\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nhrYOKaf_t9g"
      },
      "source": [
        "### Getting started\n",
        "\n",
        "#### Data\n",
        "We will try to solve the [Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/) task from Mass et al. The dataset consists of IMDB movie reviews labeled by positivity from 1 to 10. The task is to label the reviews as **negative** or **positive**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "lVnmgygj_t9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "708e94a2-899f-4831-b2be-69b73b9dbe33"
      },
      "source": [
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "#   data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "#       data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))#; ipdb.set_trace()\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"sentiment\"] = 1\n",
        "  neg_df[\"sentiment\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n",
        "\n",
        "train_df, test_df = download_and_load_datasets()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CR4TW4SzGerx",
        "outputId": "85f11d37-58f8-4f66-8a32-9796bc409587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Double-check that we've done the right thing.\n",
        "print(\"Training examples summary:\")\n",
        "display.display(train_df.describe())\n",
        "display.display(train_df.head())\n",
        "print(\"\\n#############################\\n\")\n",
        "print(\"Validation examples summary:\")\n",
        "display.display(test_df.describe())\n",
        "display.display(test_df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.50001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "count  25000.00000\n",
              "mean       0.50000\n",
              "std        0.50001\n",
              "min        0.00000\n",
              "25%        0.00000\n",
              "50%        0.50000\n",
              "75%        1.00000\n",
              "max        1.00000"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A great gangster film.Sam Mendes has directed ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I MAY have seen an episode or 2 when the show ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This movie looked like a classic in the cheesy...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is surely one of the worst films ever mad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm surprised no-one has thought of doing a mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment\n",
              "0  A great gangster film.Sam Mendes has directed ...          1\n",
              "1  I MAY have seen an episode or 2 when the show ...          1\n",
              "2  This movie looked like a classic in the cheesy...          1\n",
              "3  This is surely one of the worst films ever mad...          0\n",
              "4  I'm surprised no-one has thought of doing a mo...          1"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#############################\n",
            "\n",
            "Validation examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.50001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "count  25000.00000\n",
              "mean       0.50000\n",
              "std        0.50001\n",
              "min        0.00000\n",
              "25%        0.00000\n",
              "50%        0.50000\n",
              "75%        1.00000\n",
              "max        1.00000"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Crossfire (1947)&lt;br /&gt;&lt;br /&gt;Great Message, Gre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great film about an American G.I. who quits th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>****SPOILER ALERT**** My boyfriend, some frien...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The End Of Suburbia (TEOS) is a very useful fi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This would have to be by far the greatest seri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment\n",
              "0  Crossfire (1947)<br /><br />Great Message, Gre...          1\n",
              "1  Great film about an American G.I. who quits th...          1\n",
              "2  ****SPOILER ALERT**** My boyfriend, some frien...          0\n",
              "3  The End Of Suburbia (TEOS) is a very useful fi...          1\n",
              "4  This would have to be by far the greatest seri...          1"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYwB0uArqmex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ed4e2cff-0478-43aa-bb23-8d583b671105"
      },
      "source": [
        "train_df['sentence'].apply(lambda x : len(x))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         691\n",
              "1         658\n",
              "2        3106\n",
              "3         824\n",
              "4        1404\n",
              "         ... \n",
              "24995     629\n",
              "24996     315\n",
              "24997     954\n",
              "24998     970\n",
              "24999     665\n",
              "Name: sentence, Length: 25000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO58JLHOpzhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "969e6581-aeaf-42f2-cd91-bd350d71a21b"
      },
      "source": [
        "# mean lengh of review \n",
        "train_df['sentence'].apply(lambda x : len(x)).mean()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1325.06964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6iNailrqXZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e3c33f9c-d656-4e64-b9d9-c5cccef9651d"
      },
      "source": [
        "train_df['sentence'][0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A great gangster film.Sam Mendes has directed this beautiful movie showing another father-son camaraderie.Brilliant star-cast leading with Tom Hanks(Michael Sullivan) has done a terrific job.Great acting by him again.He is an acting legend.Great acting too from Paul Newman,Jude Law and Daniel Craig.Casting is just too good.The plot is quite good.You will enjoy the movie.A great portrayal of the gangster of the 1930's.Set in the 1930's,this will surely stand out as the zenith of all gangster movies of that era.Soundtrack is pretty good an apt to the movie.A great flick in totality showing what a father does to protect his son.Way underrated for my liking.Deserved a fully deserved 10.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGlGdM4vJ2uc",
        "colab_type": "text"
      },
      "source": [
        "# Obtain Pre-trained BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASGXbiRKJ2uc",
        "colab_type": "code",
        "outputId": "b08d28ae-9462-464d-e8a1-164c87fe56d5",
        "colab": {}
      },
      "source": [
        "# !pip install torchtext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 158kB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from torchtext) (4.37.0)\n",
            "Requirement already satisfied: sentencepiece in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from torchtext) (0.1.85)\n",
            "Requirement already satisfied: requests in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from torchtext) (2.22.0)\n",
            "Requirement already satisfied: torch in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from torchtext) (1.3.0)\n",
            "Requirement already satisfied: six in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied: numpy in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from torchtext) (1.16.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from requests->torchtext) (1.25.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from requests->torchtext) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/aims/anaconda3/envs/aims/lib/python3.7/site-packages (from requests->torchtext) (2.8)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnwOOnVcJ2ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "a70de0f923ee4c69b751d7033baa86c1",
            "932647eefdb549f1b6be741872cdc91e",
            "58d4d1448c764e3fa6bea56dd3f6787f",
            "620c9a40b8fc4345919e98827e97594a",
            "56d6a93ea50f46768b97b081f4b74b30",
            "ae31ea2d2094447495775cd7e45b5915",
            "7a2770c9b81a460da3a8520cfacf54ee",
            "a1a00c27944f4631b8d27c05b52b3a18",
            "3889329e10e346d8a609d94eb33b705a",
            "5cebf6197fbc44dbb5f3bb669924ca06",
            "b5a8326db6c64eddbd62e7cd588e1020",
            "94e5af6bd18441ceb1915ace9172e58b",
            "aac0710a3ad84c52a3b26c38dafc4203",
            "4a4b6275d4034f1d82c19bb9e3c54c6e",
            "871f594f02f84c1eb4f0054429ec0a0f",
            "b94ff2b76ff94d88a096beb2d73cb351",
            "6bbcb37539ab41c2845b1f566be71cc8",
            "32f56de0b34a4d5d8ec7e6948590c952",
            "1f9123ac1b674fde881425899994c542",
            "963db1db61844df18c85e2ff0b5f63db",
            "5ca75792a78843b2b126a133a49b1201",
            "9e9a9d92814f4309a020fcc0ec98e554",
            "491547c6bce443d68212e7afe7844bf8",
            "d2ff7999ef294352906687e8904e0d05"
          ]
        },
        "outputId": "7feece6b-83ed-4242-d9c7-d7ec792c1aec"
      },
      "source": [
        "\n",
        "\n",
        "# # define VGG16 model\n",
        "# # VGG16 = models.vgg16(pretrained=True)\n",
        "\n",
        "# DistilBERT = models.transformers()\n",
        "\n",
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "# move model to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "    # tokenizer = tokenizer.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a70de0f923ee4c69b751d7033baa86c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3889329e10e346d8a609d94eb33b705a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=546, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bbcb37539ab41c2845b1f566be71cc8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=267967963, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxAMrw7DJ2uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossPrettifier(object):\n",
        "    \n",
        "    STYLE = {\n",
        "        'green' : '\\033[32m',\n",
        "        'red'   : '\\033[91m', \n",
        "        'bold'  : '\\033[1m', \n",
        "    }\n",
        "    STYLE_END = '\\033[0m'\n",
        "    \n",
        "    def __init__(self, show_percentage=False):\n",
        "        \n",
        "        self.show_percentage = show_percentage\n",
        "        self.color_up = 'green'\n",
        "        self.color_down = 'red'\n",
        "        self.loss_terms = {}\n",
        "    \n",
        "    def __call__(self, epoch=None, **kwargs):\n",
        "        \n",
        "        if epoch is not None:\n",
        "            print_string = f'Epoch {epoch: 5d} '\n",
        "        else:\n",
        "            print_string = ''\n",
        "\n",
        "        for key, value in kwargs.items():\n",
        "            \n",
        "            pre_value = self.loss_terms.get(key, value)\n",
        "            \n",
        "            if value > pre_value:\n",
        "                indicator  = '▲'\n",
        "                show_color = self.STYLE[self.color_up]\n",
        "            elif value == pre_value:\n",
        "                indicator  = ''\n",
        "                show_color = ''\n",
        "            else:\n",
        "                indicator  = '▼'\n",
        "                show_color = self.STYLE[self.color_down]\n",
        "            \n",
        "            if self.show_percentage:\n",
        "                show_value = 0 if pre_value == 0 \\\n",
        "                             else (value - pre_value) / float(pre_value)\n",
        "                key_string = f'| {key}: {show_color}{value:3.4f}({show_value:+3.4%}) {indicator}'\n",
        "            else: \n",
        "                key_string = f'| {key}: {show_color}{value:.4f} {indicator}'\n",
        "            \n",
        "            # Trim some long outputs\n",
        "            key_string_part = key_string[:32]\n",
        "            print_string += key_string_part+f'{self.STYLE_END}\\t'\n",
        "            \n",
        "            self.loss_terms[key] = value\n",
        "            \n",
        "        print(print_string)\n",
        "reporter = LossPrettifier(show_percentage=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugm_F1OSJ2ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss)) \n",
        "            \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss \n",
        "            valid_loss +=((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "            \n",
        "            \n",
        "        # print training/validation statistics \n",
        "        \n",
        "        reporter(epoch=epoch, LossA = train_loss, LossB = valid_loss)\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "            \n",
        "    # return trained model\n",
        "    return model\n",
        "\n",
        "# loaders_scratch = {'train' : train_loader, 'valid': valid_loader, 'test' :test_loader}\n",
        "\n",
        "# # train the model\n",
        "# model_scratch = train(15, loaders_scratch, model_scratch, optimizer_scratch, \n",
        "#                       criterion_scratch, use_cuda, 'model_scratch.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itwiwBbYJ2ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "# test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPOL_1n3ghhV",
        "colab_type": "code",
        "outputId": "50fbee09-d07f-45a6-edc8-e9da95215385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDBMn3wiSX6",
        "colab_type": "text"
      },
      "source": [
        "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
        "\n",
        "## Model #1: Preparing the Dataset\n",
        "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
        "\n",
        "### Tokenization\n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with.\n",
        "\n",
        "Unfortunatly the bert tokenizer can only encode sequence lenght less or equal to 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = train_df['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512))) \n",
        "# tokenized_test = test_df['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHwjUwYgi-uL",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n",
        "\n",
        "### Padding\n",
        "After tokenization, `tokenized` is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "# max_len = 0\n",
        "# for i in tokenized_train.values:\n",
        "#     if len(i) > max_len:\n",
        "#         max_len = len(i)\n",
        "\n",
        "# padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized_train.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq",
        "colab_type": "code",
        "outputId": "799c04ec-0bea-43e4-ec61-6e58443590ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZBsYSDjzDV",
        "colab_type": "text"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_iGRNa_Ozc",
        "colab_type": "code",
        "outputId": "27f215f2-408a-423c-ad4c-f8a42f6e8f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-CQB9-kN99",
        "colab_type": "text"
      },
      "source": [
        "## Model #1: And Now, Deep Learning!\n",
        "Now that we have our model and inputs ready, let's run our model!\n",
        "\n",
        "<img src=\"http://127.0.0.1:4000/images/distilBERT/bert-distilbert-tutorial-sentence-embedding.png\" />\n",
        "\n",
        "The `model()` function runs our sentences through BERT. The results of the processing will be returned into `last_hidden_states`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39UVjAV56PJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "5eda3fe1-5ec8-4d7c-c23e-c080f549ce33"
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "if use_cuda:\n",
        "    input_ids = input_ids.cuda()\n",
        "    attention_mask = attention_mask.cuda()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f798d7e0b4ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mtfmr_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfmr_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mposition_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, max_seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 36.62 GiB (GPU 0; 15.90 GiB total capacity; 450.24 MiB already allocated; 14.66 GiB free; 468.00 MiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoCep_WVuB3v",
        "colab_type": "text"
      },
      "source": [
        "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our logitics regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9t60At16PVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZVU66Gurr-",
        "colab_type": "text"
      },
      "source": [
        "The labels indicating which sentence is positive and negative now go into the `labels` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3fX2yh6PTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = batch_1[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoEvM2evRx1",
        "colab_type": "text"
      },
      "source": [
        "## Model #2: Train/Test Split\n",
        "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Kw-MIwJ2uc",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://jalammar.github.io/images/distilBERT/sentiment-classifier-1.png\" />\n",
        "\n",
        "Under the hood, the model is actually made up of two model.\n",
        "\n",
        "* DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n",
        "* The next model, a basic Logistic Regression model from scikit learn will take in the result of DistilBERT’s processing, and classify the sentence as either positive or negative (1 or 0, respectively).\n",
        "\n",
        "The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYM9oAkLJ2uk",
        "colab_type": "code",
        "outputId": "603afded-4758-40ce-ba40-1f16427658de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "## TODO: Specify data loaders\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "\n",
        "\n",
        "# define training, valid and test data directories\n",
        "data_dir = './aclImdb/'\n",
        "train_dir = os.path.join(data_dir, 'train/')\n",
        "valid_dir = os.path.join(data_dir, 'valid/')\n",
        "test_dir = os.path.join(data_dir, 'test/')\n",
        "\n",
        "# data_transform = transforms.Compose([\n",
        "#     transforms.RandomResizedCrop(224),\n",
        "#     transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
        "# #     transforms.RandomRotation(10),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "#     ])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir)\n",
        "# valid_data = datasets.ImageFolder(valid_dir)\n",
        "test_data = datasets.ImageFolder(test_dir)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    num_workers=num_workers)\n",
        "# valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
        "#     num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7b3b332f3ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#     ])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# valid_data = datasets.ImageFolder(valid_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise (RuntimeError(\"Found 0 files in subfolders of: \" + self.root + \"\\n\"\n\u001b[0;32m---> 97\u001b[0;31m                                 \"Supported extensions are: \" + \",\".join(extensions)))\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found 0 files in subfolders of: ./aclImdb/train/\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo-RpErIJ2um",
        "colab_type": "text"
      },
      "source": [
        "### (IMPLEMENTATION) Model Architecture\n",
        "\n",
        "Use transfer learning to create a CNN to classify dog breed.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y8ZoLH3J2un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "## TODO: Specify model architecture \n",
        "# Load the pretrained model from pytorch\n",
        "model_transfer = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze training for all \"features\" layers\n",
        "for param in model_transfer.features.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "import torch.nn as nn\n",
        "\n",
        "n_inputs = model_transfer.classifier[6].in_features\n",
        "\n",
        "# add last linear layer (n_inputs -> 5 flower classes)\n",
        "# new layers automatically have requires_grad = True\n",
        "last_layer = nn.Linear(n_inputs, 133)\n",
        "\n",
        "model_transfer.classifier[6] = last_layer\n",
        "\n",
        "# check to see that your last layer produces the expected number of outputs\n",
        "print(model_transfer.classifier[6].out_features)\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7QmbTyZJ2uo",
        "colab_type": "text"
      },
      "source": [
        "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaf8jJO_J2uo",
        "colab_type": "text"
      },
      "source": [
        "__Answer:__ \n",
        "\n",
        "- I used the pretrained vgg16 and just changed the last layer to output 133 classes.\n",
        "- The reason behind using the vgg16 is the it's a pre-trained model on huge images and by freezing the weight we can take advantage of what the model learned from the original training data. \n",
        "- I thin kthis architecture is suitable for the dog breed problem because the vgg16 also was trained on imagenet and some of those have some caracteristic in common with my task. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPCGT9nRJ2up",
        "colab_type": "text"
      },
      "source": [
        "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
        "\n",
        "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS95TPR6J2up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwUFvwVcJ2uq",
        "colab_type": "text"
      },
      "source": [
        "### (IMPLEMENTATION) Train and Validate the Model\n",
        "\n",
        "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vqrZB7nJ2uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaders_transfer = {'train' : train_loader, 'valid': valid_loader, 'test' :test_loader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SlgXZYLJ2ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "model_transfer = train(15, loaders_transfer, model_transfer, \n",
        "                       optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8eKaokMJ2uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model that got the best validation accuracy (uncomment the line below)\n",
        "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUU5VUBhJ2uy",
        "colab_type": "text"
      },
      "source": [
        "### (IMPLEMENTATION) Test the Model\n",
        "\n",
        "Try out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NegpbjoiJ2uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Yp3RBRJ2u0",
        "colab_type": "text"
      },
      "source": [
        "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
        "\n",
        "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxTMZlp_J2u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/data/dog_images/train/001.Affenpinscher/Affenpinscher_00001.jpg'\n",
        "data_transfer = {'train' : train_data, 'valid': valid_data, 'test' :test_data}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hHtZtFFJ2u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TODO: Write a function that takes a path to an image as input\n",
        "### and returns the dog breed that is predicted by the model.\n",
        "\n",
        "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
        "class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].classes]\n",
        "\n",
        "def predict_breed_transfer(img_path):\n",
        "    # load the image and return the predicted breed\n",
        "    \n",
        "    data_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    \n",
        "    img = data_transform(Image.open(img_path))\n",
        "    if use_cuda:\n",
        "        img = img.cuda()\n",
        "        \n",
        "    # PyTorch pretrained models expect the Tensor dims to be (num input imgs, num color channels, height, width).\n",
        "    # Currently however, we have (num color channels, height, width); let's fix this by inserting a new axis.\n",
        "    img = img.unsqueeze(0)  # Insert the new axis at index 0 i.e. in front of the other axes/dims. \n",
        "    \n",
        "    prediction = model_transfer(img)  # Returns a Tensor of shape (batch, num class labels)\n",
        "\n",
        "    \n",
        "    return class_names[prediction.data.cpu().numpy().argmax()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nY-nPjpa4wDr"
      },
      "source": [
        "---\n",
        "\n",
        "# <h2>About the Authors:</h2> \n",
        "\n",
        "<a href=\"https://salomonkabongo.wixsite.com/datascientist\">Salomon Kabongo KABENAMUALU</a>, Master degree student at <a href=\"https://aims.ac.za/\">the African Institute for mathematical SCiences (AIMS South Africa)</a> his research focused on the use machine learning technique in the field of Natural Language Processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xDX0h3pa4wDt"
      },
      "source": [
        "References : <a href=\"https://machinelearningmastery.com/deep-learning-bag-of-words-model-sentiment-analysis/\"> How to Develop a Deep Learning Bag-of-Words Model for Predicting Movie Review Sentiment</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdkZJcdh4wDu"
      },
      "source": [
        "Copyright &copy; 2019. This notebook and its source code are released under the terms of the <a href=\"https://www.apache.org/licenses/LICENSE-2.0\">Apache License 2.0</a>."
      ]
    }
  ]
}